---
title: "motifs-pipeline"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{motifs-pipeline}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Cette vignette montre comment utiliser les fonctions du package Motifs. Elle sert d'exemple au pipeline d’analyse des motifs d’un corpus à l'aide du package MotiveR. Le package est construit sous la forme d'un enchaînement logique de fonctions allant du :

- Preprocessing des données (annotation et transformation en motifs).
- Visualisations exploratoires et statistiques : histogrammes de fréquence, tf-idf, acp.
- Calcul statistiques de spécificités permettant l'analyse comparative des oeuvres du corpus.
- Retours aux textes selon deux approches : sur l'ensemble des motifs ou à partir d'un motifs cible.

### Introduction

Definissez d'abord les paramètres et charger les librairies. Suivant les besoins, charger `explor` our `Factoshiny` pour la visualisation des ACP.

Les paramètres sont les suivants : 
- path : chemin vers le dossier contenant les fichiers .txt constituant le corpus d'analyse. Exemple : "~/MotiveR/extdata/corpus/"
- save_output : si l'on souhaite sauvegarder les résultats à la suite de l'exécution des fonctions. Exemple : TRUE / FALSE. 
- overwrite : est-ce que les résultats doivent écraser les sorties précédentes ? Exemple : TRUE / FALSE.
- n_grams : longueur de la séquence de n_grams des motifs analysés. Ex : 1 à 7.
- frequence : filtre de frequence pour le retour aux textes. Ce paramètre permet de limiter le temps de calcul et de limiter le nombre de motifs analysés.
- len_context : longueur du contexte d'analyse dans le retour au texte (droite et gauche, càd avant le motif et après le motif), définit en nombre de mots. Exemple : 10.

```{r setup}
# Charger le package (apres l'avoir installe)
library(MotiveR)

# installer and charger les packages externes
# libraries = c("Factoshiny", "FactoMineR", "explor")
# lapply(libraries, function(x) if (!(x %in% installed.packages())) {
#   install.packages(x, repos = "https://cran.rstudio.com")
# })
# lapply(libraries, library, quietly = TRUE, character.only = TRUE)

# manipulation de données
library(dplyr)

# Pour creer des ACP interactive
library(FactoMineR)
# Charger explor pour realiser des ACP interactive avec shiny.
library(explor)
# ou Factoshiny
library(Factoshiny)

# Parametres:
path <- system.file("extdata", "corpus-test", package = "MotiveR") # chemin du corpus
save_output <- FALSE # Sauvegarde resultats
overwrite <- FALSE # ecrase resultats precedents
n_grams <- 4 # longueur de la sequence n-gram
frequence <- 10 # filtre de frequence pour le retour aux textes (limite le temps de calcul)
len_context <- 4 # longueur du contexte d'analyse

```

### Preparation des donnees

#### Annotation et etiquetage

Lors de la premiere utilisation, le modèle d'étiquetage est téléchargé ce qui peut prendre un peu de temps.

- En deux fois: annotation et transformation du corpus en motifs.

```{r annotation, eval=FALSE, message=FALSE, include=TRUE, results='hide'}
# UDpipe annotation
corpus_annote <- annotation_udpipe(path = path,
                                  save_output = save_output,
                                  overwrite = overwrite)
# transformation en motifs du corpus annote
corpus_motifs <- regex_corpus_udpipe(corpus = corpus_annote,
                                    save_output = save_output,
                                    overwrite = overwrite)
```

- Ou en une fois grâce la fonction `tag_motif_pipeline`

```{r tag_motif_pipeline, message=FALSE, results='hide'}
corpus_motifs <- tag_motif_pipeline(path = path,
                                   save_output = save_output,
                                   overwrite = overwrite)
```

#### Transformation en n-grams

Sélection de la longueur du motif en nombre de ngrams. Par exemple, un ngram de 4 constituera des motifs du type : "NC de le NC".

```{r choix_nb_ngrams, message=FALSE, results='hide'}
corpus_grams <-  choix_nb_ngrams(
  n_grams,
  corpus = corpus_motifs,
  save_output = save_output,
  overwrite = overwrite
)
```

### Analyze

#### Histogrammes des motifs:

Fonction permettant la création d'une visualisation sous la forme d'un histogramme de n motifs calculé à partir des motifs les plus fréquents (choix du nombre de motifs à afficher grâce au paramètre nmots = n). On peut choisir de calculer cela à partir de la fréquence absolu (paramètre "abs") ou de la fréquence relative ("rel") qui normalise un peu la fréquence :

```{r motifs_histogram, message=FALSE, results='hide', fig.width = 6, fig.height=3}
motifs_histogram(corpus_grams = corpus_grams,
                 nmots = 10,
                 freq = "rel")
```

#### Analyse TFIDF :

Fonctions permettant de calculer au sein du corpus les fréquences TF-IDF (motif_tf_idf) et de créer des histogrammes (plot_tf_idf) de ces motifs à partir de ce score. 
> Pour info : le Tf-idf (term-frequency – inverse document frequency) est une mesure permettant de se pencher sur les spécificités propres à chaque document du corpus, ce qui les distingue les uns des autres. Contre une pondération « locale » (à l’échelle du document), le tf-idf permet une pondération « globale » (à l’échelle du corpus) des termes, de leur représentativité dans le corpus.

```{r motifs_tf_idf_sep, out.width="100%", message=FALSE, results='hide', fig.width = 8, fig.height=3}
corpus_words_ngrams <- motifs_tf_idf(
  corpus_grams = corpus_grams,
  save_output = save_output,
  overwrite = overwrite
)
plot_tf_idf(corpus_words_ngrams, n_motifs = 2, plot_type = "sep")
```

Grâce au paramètre plot_type, la visualisation peut être séparée ("sep") ou groupée ("group").

- 3 motifs sur un seul grqphique:
```{r motifs_tf_idf_group, out.width="100%", message=FALSE, results='hide', fig.width = 6, fig.height=4, out.width="100%"}
plot_tf_idf(corpus_words_ngrams, n_motifs = 3, plot_type = "group")
```

#### ACP avec FactoMineR:

Fonction permettant de produire une analyse en composante princiaple à partir des motifs du corpus. Cette fonction prepare_acp exécute avant le calcul de l'ACP une normalisation zscore des fréquences. Différentes fonctions de visualisation sont ensuite disponibles, via une application Shiny (explor), via Factoshiny ou avec la fonction du package. Un filtre de fréquence peut être appliqué permettant de réduire le nombre d'observations étudié.

```{r FactoMineRPCA, fig.width = 6, fig.height=3, out.width="100%"}
corpus_norm <- prepare_acp(corpus_grams = corpus_grams)
res.pca <- FactoMineR::PCA(corpus_norm, graph=TRUE)
```

#### Visualisation avec explor:
```{r explor, eval=FALSE, message=FALSE, include=TRUE, results='hide'}
res.shiny <- explor::explor(res.pca)
```

#### Visualisation avec Factoshiny:
```{r Factoshiny, eval=FALSE, message=FALSE, include=TRUE, results='hide'}
res.shiny <- Factoshiny::PCAshiny(res.pca)
```

#### ACP avec la fonction du package
```{r motifs_acp, out.width="100%", message=FALSE, results='hide', fig.width = 6, fig.height=3, out.width="100%"}
motifs_acp(plot_type = "var", corpus_grams = corpus_grams, n_motifs=10)
motifs_acp(plot_type = "motif", corpus_grams = corpus_grams, n_motifs=10)
motifs_acp(plot_type = "var+motif", corpus_grams = corpus_grams, n_motifs=10)
```

#### Realiser des statistiques sur les motifs
```{r motifs_stats, message=FALSE, results='hide'}
df_stats <- motifs_stats(
  corpus_grams = corpus_grams,
  save_output = save_output,
  overwrite = overwrite
)
```

#### Calcul de specificites

Cette fonction permet d'exécuter un calcul de spécificité des motifs dans le corpus à l'étude ; il se fonde sur le calcul inventé par Pierre Lafon en 1984 (voir LAFON, Pierre, *Dépouillements et statistiques en lexicométrie*, Genève-Paris, Slatkine-Champion, 1984). Plutôt que d’en rester au calcul de la fréquence relative ou du Tf-idf, P. Lafon propose un calcul de spécificité qui normalise cette fréquence relative en prenant en compte le fait que la distribution des individus dans un texte ne suit pas une loi normale, mais est plutôt proche d’une loi hypergéométrique. Il permet ainsi de comparer les motifs des différents textes entre eux et d'analyser de façon comparative lesquels sont les plus spécifiques d'un texte du corpus par rapport aux autres.

```{r calcul_specificites, message=FALSE, results='hide'}
calcul_spec_freq <- calcul_specificites(
  save_freq = TRUE,
  retrait_frequence_1 = TRUE,
  corpus_grams = corpus_grams,
  save_output = save_output,
  overwrite = overwrite
)
```

#### Retour aux textes

La fonction de retour aux texte permet de produire un tableau de concordance pour analyser les résultats. Ce tableau contient les scores de spécificités ce qui permet d'ordonnancer les résultats à partir des différents textes que l'on souhaite analyser. Deux approches sont possibles : 

- Soit l'on explore la table de l'ensemble des motifs, dans une démarche exploratoire.
- Soit l'on part d'un motif spécifique pour étudier l'ensemble de ses occurrences dans le corpus étudié.

Dans les deux cas, on peut se fonder sur les scores de spécificités pour interpréter les résultats. Les paramètres définissent :

- frequence : le seuil de fréquence minimal (seul les motifs au dessus de ce seuil seront affichés dans la table de concordance).
- len_context : la longueur de la fenêtre contextuel (en nombre de mots).
- n_grams : la longueur de notre séquence de motifs, exprimée en ngrams.
- corpus_grams : une dataframe, résultat de la fonction choix_nb_ngrams.
- corpus_spect : une dataframe, résultat de la fonction calcul_specificites.
- save_output : sauvegarde ou non les résultats.
- overwrite : écrase ou non les résultats.

```{r retour_texte_specificites, message=FALSE, results='hide'}
retour_text_spec <- retour_texte_specificites(
  frequence = frequence,
  len_context = len_context,
  n_grams = n_grams,
  corpus_grams = corpus_grams,
  corpus_spec = calcul_spec_freq,
  save_output = save_output,
  overwrite = overwrite
)
```

#### Retour aux textes a partir d'un motif

```{r retour_texte_specificites_un_motif, message=FALSE, results='hide'}
retour_text_spec_un_motif <- retour_texte_specificites_un_motif(
  motif_cible = "le NC de le",
  len_context = len_context,
  n_grams = n_grams,
  corpus_grams = corpus_grams,
  corpus_spec = calcul_spec_freq,
  save_output = save_output,
  overwrite = overwrite
)
```


